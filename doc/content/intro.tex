This report is the result of a reading course, done by students on the Computer Engineering master degree at Department of Engineering, Aarhus university. The content of the course is based on the Udacity online course "Intro to Parallel Programming", which is a introduction to parallel programming, using CUDA. To further extend the theory in the reading course, additional topics and in-depth topics was added, primarily in understanding of the hardware and programming model of CUDA GPU's.\\
This report is meant to describe the curriculum of a possible course in CUDA programming, and therefore contains in depth theory of relevant subjects with in the the area of parallel programming and CUDA programming.

	\section{Report Structure}
	\label{sec-rep-struc}
	As the report is meant to describe a curriculum of a possible course, it is a constant attempt through out the report to keep thing separated and in a order which promotes the best approach to learning the theory. Therefore this \cref{ch-intro}, provides an introduction to the report, as well as some general terms and information necessary to understanding why parallel computing is beneficial in modern day computing. These are terms such as step and work complexity, latency vs bandwidth, and how code in general can be parallelized.\\
	\Cref{ch-hw-gpu-hardware-architecture} provides a general understanding and overview over the GPU hardware architecture. This includes historical aspects, GPU and CPU interaction architecture, GPU architecture and how these can vary.\\
	In \cref{ch-programming-model} a general walk through of the GPU programming model along with specifics for the CUDA programming model. The programming model contains the following subjects: kernels, threats, memory, synchronization, stream and dynamic parallelism.\\
	Following this \cref{ch-patterns} dives into some of the parallel communication patterns such as map, gather, scatter, stencil and transpose.\\
	\Cref{ch:algorithms} looks at some of the commonly used GPU algorithms, which creates a foundation for further writing massive parallel programs. The algorithms featured is: reduce, scan, histogram, sort, compact and allocate.\\
	The \cref{ch-opti-intro} looks at how we can use the knowledge achieved in \cref{ch-hw-gpu-hardware-architecture} and \cref{ch-programming-model} to optimize performance of CUDA programs, this includes optimization of memory access and thread divergence.\\
	In \cref{ch-app} we look at some of the applications for GPU programming, this includes matrix multiplication, sparce/dense matricies and graphs. A description of the exercises provided by the Udacity course, along with a description of what is required to solve the exercise will also be provided.\\
	Finally in \cref{ch-libraries} some of the available libraries for CUDA and GPU programming is described.