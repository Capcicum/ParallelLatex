Before introducing anything related to parallel programming, it is a good idea to know why we need parallel programming, and why we have seen a paradigm shift towards parallel computing.\\
First of all, almost all computer nowadays contains multi-core processors, from desktop/laptop computers to servers, smartphones, even minicomputers at credit card size such as a Raspberry PI. This change from single core to multi-core processors arrived as multiple cores became a more efficient way of improving performance compared to increasing speed of a single core.\\
This change made it so that a simple program, running sequential code where each instruction is executed one at a time will no longer fully utilize the performance of these processors. Instead, its now required to divide the work out to each of the individual cores, so each core is utilized to improve performance. One of the problems encountered when running code on multiple processors if often feeding each of the core's data, and synchronizing data, which, while increasing throughput, also increases latency on computations. Why this can be a beneficial trade-off, and why it affects our programs will be further described in \cref{sec-lat-vs-band}.\\
Another thing worth noting is that while some of the concepts described in this report might apply to these regular multi-core processors as well, this report will primarily focus on massively parallel processor, where we have a very large number of cores, such as in NVIDIA's CUDA GPU's, and therefore rely on writing parallel scalable code.