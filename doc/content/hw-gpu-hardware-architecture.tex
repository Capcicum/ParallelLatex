Modern software programmers have been using standard processing unit architectures, such as Central Processing Units (CPUs) for decades, where highly developed compilers help utilizing the underlying hardware.
However, Graphical Processing Unit (GPU) programmers must have considerable knowledge of the underlying hardware architecture to fully achieve optimized and efficient performance results.
Achieving such knowledge can be difficult as GPU hardware architecture is complex and comes in many variations.
This is a result of the major development of which GPUs has been undergoing, from the first GPUs emerging back in the late 1990s to the newest upcoming architectures not yet released.

The following sections will provide a understanding of how GPU hardware architecture is structured and how it works.
The first section briefly describes the early evolution of GPUs, leading to the birth of the GPUs used today, also defined as General Purpose Graphical Processing Unit (GPGPUs).
Hereafter, a type of GPGPU, namely the CUDA GPU hardware architecture is described in details, including its memory model.
Lastly, alternative GPU hardware architectures is presented, in addition with a description of 
the future architectures not yet launched.



 