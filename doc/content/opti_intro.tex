As previously mentioned, when parallelizing a task, the goal is to achieve a higher throughput of the task performed by the program. While parallelizing could be assumed to directly improve the throughput, one has to take different things into account, one of the most important, how well is the program optimized for the task it performs. The goal when optimizing a program is to make the best or most effective use of the data, calculations, and resources for the task to be performed. Specifically for optimization of CUDA programs, we will look at three different aspects, general optimization, memory access optimization and threat divergence influence on performance. These three aspects will be discussed in the following sections, where the focus will be on non-application specific optimization, providing strategies for optimization which can be applied to a broad range of programs. 