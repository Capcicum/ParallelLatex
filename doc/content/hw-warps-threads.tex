This section covers the execution model of the GPU.
Based on Michael J. Flynn proposed Flynn's taxonomy \cite{Flynn1972}, used to identify computer architectures execution models, four categories were defined:

\begin{itemize}
	\item \textit{Single Instruction, Single Data} (SISD)
	\item \textit{Single Instruction, Multiple Data} (SIMD)
	\item \textit{Multiple Instruction, Single Data} (MISD)
	\item \textit{Multiple Instruction, Multiple Data} (MIMD)
\end{itemize}

The idea is to define how many instructions is performed on how much data.
For instance, SISD only allows for one instruction to be peformed on a single data input at a time, corresponding to a single-core CPU.
Based on SIMD, Nvidia introduced a new execution model \cite{Nvidia2009}, known as \textit{Single Instruction, Multiple Threads} (SIMT).
A function running on the GPU is defined as a \textit{Kernel} (further descirbed in \cref{sec-pm-kernels}).
Once a Kernel is executed on the GPU, it is potentially handled by thousands of lightweighted threads running simultaneously. 
As described in \cref{sec-hw-gpu-arhchitecture}, threads are grouped into \textit{thread blocks}, which are to be executed on SMs.
Once divided into blocks, the threads are dispatched by the Global Scheduler onto the SMs for execution.



% Branches i kode -> helst ikke